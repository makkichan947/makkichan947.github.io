+++
date = '2025-10-20T21:33:42+08:00'
draft = false
title = 'å·ç§¯ç¥ç»ç½‘ç»œ'
comments = true
weight = 2
+++

# å·ç§¯ç¥ç»ç½‘ç»œ

å·ç§¯ç¥ç»ç½‘ç»œï¼ˆConvolutional Neural Networks, CNNï¼‰æ˜¯æ·±åº¦å­¦ä¹ ä¸­ä¸“é—¨ç”¨äºå¤„ç†å›¾åƒæ•°æ®çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œåœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå–å¾—äº†å·¨å¤§æˆåŠŸã€‚

## ğŸ–¼ï¸ å›¾åƒå¤„ç†åŸºç¡€

### å›¾åƒè¡¨ç¤º
å›¾åƒå¯ä»¥è¡¨ç¤ºä¸ºä¸‰ç»´å¼ é‡ï¼š
- **é«˜åº¦** (Height)
- **å®½åº¦** (Width)
- **é€šé“æ•°** (Channels): RGBå›¾åƒä¸º3ï¼Œç°åº¦å›¾åƒä¸º1

### å·ç§¯æ“ä½œ
å·ç§¯æ˜¯CNNçš„æ ¸å¿ƒæ“ä½œï¼Œé€šè¿‡åœ¨å›¾åƒä¸Šæ»‘åŠ¨æ»¤æ³¢å™¨æ¥æå–ç‰¹å¾ï¼š

**æ•°å­¦å®šä¹‰**ï¼š
$$(I * K)_{x,y} = \sum_{i}\sum_{j} I_{x+i, y+j} K_{i,j}$$

## ğŸ” å·ç§¯å±‚

### å·ç§¯æ ¸
å·ç§¯æ ¸ï¼ˆKernel/Filterï¼‰æ˜¯ç”¨äºç‰¹å¾æå–çš„å°çŸ©é˜µï¼š

**è¾¹ç¼˜æ£€æµ‹**ï¼š
```
[-1, -1, -1]
[-1,  8, -1]
[-1, -1, -1]
```

**æ¨¡ç³Šæ»¤æ³¢**ï¼š
```
[1, 1, 1]
[1, 1, 1]
[1, 1, 1]
```
ï¼ˆé™¤ä»¥9è¿›è¡Œå½’ä¸€åŒ–ï¼‰

### å·ç§¯å‚æ•°

**æ­¥é•¿ (Stride)**ï¼šå·ç§¯æ ¸æ»‘åŠ¨çš„æ­¥é•¿
**å¡«å…… (Padding)**ï¼šå›¾åƒè¾¹ç¼˜å¡«å……
**è¾“å‡ºå°ºå¯¸**ï¼š$\frac{W - F + 2P}{S} + 1$

## ğŸŠ æ± åŒ–å±‚

### æœ€å¤§æ± åŒ– (Max Pooling)
ä¿ç•™åŒºåŸŸå†…çš„æœ€å¤§å€¼ï¼š
```
è¾“å…¥ï¼š
[[1, 3],
 [2, 4]]

æœ€å¤§æ± åŒ–ï¼š
[[4]]
```

### å¹³å‡æ± åŒ– (Average Pooling)
è®¡ç®—åŒºåŸŸå†…å¹³å‡å€¼ï¼š
```
è¾“å…¥ï¼š
[[1, 3],
 [2, 4]]

å¹³å‡æ± åŒ–ï¼š
[[2.5]]
```

## ğŸ—ï¸ ç»å…¸CNNæ¶æ„

### LeNet-5 (1998)

** Yann LeCunçš„å¼€åˆ›æ€§å·¥ä½œ **

**æ¶æ„**ï¼š
```
è¾“å…¥(32Ã—32) â†’ Conv(6@28Ã—28) â†’ Pool(6@14Ã—14) â†’ Conv(16@10Ã—10) â†’ Pool(16@5Ã—5) â†’ FC(120) â†’ FC(84) â†’ FC(10)
```

### AlexNet (2012)

**ImageNet 2012å† å†›**

**åˆ›æ–°ç‚¹**ï¼š
- ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°
- å¼•å…¥Dropouté˜²æ­¢è¿‡æ‹Ÿåˆ
- ä½¿ç”¨GPUåŠ é€Ÿè®­ç»ƒ
- æ•°æ®å¢å¼ºæŠ€æœ¯

**æ¶æ„**ï¼š
```
è¾“å…¥(227Ã—227Ã—3) â†’ Conv+ReLU+Pool â†’ Conv+ReLU+Pool â†’ Conv+ReLU â†’ Conv+ReLU â†’ Conv+ReLU+Pool â†’ FC+Dropout â†’ FC+Dropout â†’ FC(1000)
```

### VGGNet (2014)

**ç®€æ´è€Œæœ‰æ•ˆçš„æ¶æ„**

**ç‰¹ç‚¹**ï¼š
- ä½¿ç”¨3Ã—3å°å·ç§¯æ ¸
- å †å å¤šä¸ªå·ç§¯å±‚
- éªŒè¯äº†ç½‘ç»œæ·±åº¦çš„é‡è¦æ€§

**VGG16æ¶æ„**ï¼š
```
è¾“å…¥(224Ã—224Ã—3) â†’ 2Ã—Conv3Ã—3 â†’ Pool â†’ 2Ã—Conv3Ã—3 â†’ Pool â†’ 3Ã—Conv3Ã—3 â†’ Pool â†’ 3Ã—Conv3Ã—3 â†’ Pool â†’ 3Ã—Conv3Ã—3 â†’ Pool â†’ FC(4096) â†’ FC(4096) â†’ FC(1000)
```

### ResNet (2015)

**æ®‹å·®ç½‘ç»œï¼Œè§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜**

**æ®‹å·®å—**ï¼š
$$y = F(x) + x$$

**åˆ›æ–°ç‚¹**ï¼š
- å¼•å…¥æ®‹å·®è¿æ¥
- å…è®¸è®­ç»ƒæ›´æ·±çš„ç½‘ç»œ
- ResNet-152: 152å±‚

## ğŸ¯ ç›®æ ‡æ£€æµ‹

### R-CNNç³»åˆ—

**R-CNN (2014)**ï¼š
1. ä½¿ç”¨é€‰æ‹©æ€§æœç´¢ç”Ÿæˆå€™é€‰æ¡†
2. å¯¹æ¯ä¸ªå€™é€‰æ¡†æå–CNNç‰¹å¾
3. ä½¿ç”¨SVMè¿›è¡Œåˆ†ç±»

**Fast R-CNN (2015)**ï¼š
- å…±äº«å·ç§¯ç‰¹å¾
- å¼•å…¥RoIæ± åŒ–å±‚
- å¤šä»»åŠ¡æŸå¤±å‡½æ•°

**Faster R-CNN (2015)**ï¼š
- å¼•å…¥RPNï¼ˆRegion Proposal Networkï¼‰
- ç«¯åˆ°ç«¯è®­ç»ƒ
- å®æ—¶ç›®æ ‡æ£€æµ‹

### YOLOç³»åˆ—

**YOLO (You Only Look Once)**ï¼š
- å•é˜¶æ®µæ£€æµ‹å™¨
- ç›´æ¥é¢„æµ‹è¾¹ç•Œæ¡†å’Œç±»åˆ«
- é€Ÿåº¦å¿«ï¼Œé€‚åˆå®æ—¶åº”ç”¨

**YOLOv3**ï¼š
- å¤šå°ºåº¦é¢„æµ‹
- æ›´å¥½çš„å°ç›®æ ‡æ£€æµ‹
- å¹³è¡¡é€Ÿåº¦å’Œç²¾åº¦

## ğŸ”„ åå‘ä¼ æ’­

### å·ç§¯å±‚æ¢¯åº¦

**æƒé‡æ¢¯åº¦**ï¼š
$$\frac{\partial L}{\partial K} = \frac{\partial L}{\partial Y} * X^T$$

**è¾“å…¥æ¢¯åº¦**ï¼š
$$\frac{\partial L}{\partial X} = \frac{\partial L}{\partial Y} * K^T$$

### æ± åŒ–å±‚æ¢¯åº¦

**æœ€å¤§æ± åŒ–**ï¼š
- æœ€å¤§å€¼ä½ç½®çš„æ¢¯åº¦ä¸º1
- å…¶ä»–ä½ç½®çš„æ¢¯åº¦ä¸º0

**å¹³å‡æ± åŒ–**ï¼š
- æ‰€æœ‰ä½ç½®çš„æ¢¯åº¦ç›¸ç­‰

## ğŸš€ ç¼–ç¨‹å®ç°

### PyTorchå®ç°

```python
import torch
import torch.nn as nn

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()

        # å·ç§¯å±‚
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)

        # æ± åŒ–å±‚
        self.pool = nn.MaxPool2d(2, 2)

        # å…¨è¿æ¥å±‚
        self.fc1 = nn.Linear(128 * 4 * 4, 512)
        self.fc2 = nn.Linear(512, 10)

        # æ¿€æ´»å‡½æ•°
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        # å·ç§¯ + æ¿€æ´» + æ± åŒ–
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = self.pool(self.relu(self.conv3(x)))

        # å±•å¹³
        x = x.view(-1, 128 * 4 * 4)

        # å…¨è¿æ¥å±‚
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)

        return x
```

### æ‰‹åŠ¨å®ç°å·ç§¯

```python
def conv2d(input_tensor, kernel, stride=1, padding=0):
    """æ‰‹åŠ¨å®ç°2Då·ç§¯"""
    # è¾“å…¥å°ºå¯¸
    batch_size, in_channels, in_height, in_width = input_tensor.shape

    # å·ç§¯æ ¸å°ºå¯¸
    out_channels, in_channels, kernel_height, kernel_width = kernel.shape

    # è¾“å‡ºå°ºå¯¸è®¡ç®—
    out_height = (in_height + 2 * padding - kernel_height) // stride + 1
    out_width = (in_width + 2 * padding - kernel_width) // stride + 1

    # è¾“å‡ºå¼ é‡
    output = np.zeros((batch_size, out_channels, out_height, out_width))

    # å¡«å……è¾“å…¥
    if padding > 0:
        padded_input = np.pad(input_tensor,
                            ((0, 0), (0, 0), (padding, padding), (padding, padding)),
                            mode='constant')
    else:
        padded_input = input_tensor

    # å·ç§¯æ“ä½œ
    for b in range(batch_size):
        for oc in range(out_channels):
            for oh in range(out_height):
                for ow in range(out_width):
                    # æå–è¾“å…¥å—
                    input_block = padded_input[
                        b,
                        :,
                        oh*stride : oh*stride + kernel_height,
                        ow*stride : ow*stride + kernel_width
                    ]

                    # è®¡ç®—å·ç§¯
                    output[b, oc, oh, ow] = np.sum(input_block * kernel[oc])

    return output
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### GPUåŠ é€Ÿ
```python
# æ£€æŸ¥GPUå¯ç”¨æ€§
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# æ¨¡å‹ç§»åŠ¨åˆ°GPU
model = CNN().to(device)
inputs = inputs.to(device)
```

### æ‰¹é‡å½’ä¸€åŒ–
```python
# åœ¨å·ç§¯å±‚åæ·»åŠ BNå±‚
self.bn1 = nn.BatchNorm2d(32)
self.bn2 = nn.BatchNorm2d(64)
self.bn3 = nn.BatchNorm2d(128)
```

### æ®‹å·®è¿æ¥
```python
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)

        # æ®‹å·®è¿æ¥
        self.shortcut = nn.Sequential()
        if in_channels != out_channels:
            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        residual = x
        x = self.bn1(self.conv1(x))
        x = self.bn2(self.conv2(x))
        x += self.shortcut(residual)
        return x
```

## ğŸ¨ è®¡ç®—æœºè§†è§‰åº”ç”¨

### å›¾åƒåˆ†ç±»
- **ImageNet**ï¼š1000ç±»å›¾åƒåˆ†ç±»
- **CIFAR-10/100**ï¼š10/100ç±»å°å›¾åƒåˆ†ç±»
- **MNIST**ï¼šæ‰‹å†™æ•°å­—è¯†åˆ«

### ç›®æ ‡æ£€æµ‹
- **è¾¹ç•Œæ¡†å›å½’**ï¼šé¢„æµ‹ç›®æ ‡ä½ç½®
- **åˆ†ç±»**ï¼šåˆ¤æ–­ç›®æ ‡ç±»åˆ«
- **ç½®ä¿¡åº¦**ï¼šé¢„æµ‹æ£€æµ‹çš„å‡†ç¡®æ€§

### è¯­ä¹‰åˆ†å‰²
- **FCN**ï¼šå…¨å·ç§¯ç½‘ç»œ
- **U-Net**ï¼šåŒ»å­¦å›¾åƒåˆ†å‰²
- **DeepLab**ï¼šå¤šå°ºåº¦ç‰¹å¾èåˆ

### å›¾åƒç”Ÿæˆ
- **GAN**ï¼šç”Ÿæˆå¯¹æŠ—ç½‘ç»œ
- **VAE**ï¼šå˜åˆ†è‡ªç¼–ç å™¨
- **Style Transfer**ï¼šé£æ ¼è¿ç§»

## ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡

### åˆ†ç±»ä»»åŠ¡
- **Top-1å‡†ç¡®ç‡**ï¼šé¢„æµ‹ç±»åˆ«ä¸çœŸå®ç±»åˆ«å®Œå…¨åŒ¹é…
- **Top-5å‡†ç¡®ç‡**ï¼šé¢„æµ‹çš„5ä¸ªç±»åˆ«ä¸­åŒ…å«çœŸå®ç±»åˆ«

### ç›®æ ‡æ£€æµ‹
- **mAP (mean Average Precision)**ï¼šå¹³å‡ç²¾åº¦å‡å€¼
- **IoU (Intersection over Union)**ï¼šé¢„æµ‹æ¡†ä¸çœŸå®æ¡†çš„é‡å åº¦

### è¯­ä¹‰åˆ†å‰²
- **Pixel Accuracy**ï¼šåƒç´ çº§å‡†ç¡®ç‡
- **IoU (Intersection over Union)**ï¼šç±»åˆ«çº§IoU
- **mIoU**ï¼šå¹³å‡IoU

## ğŸ”§ å®ç”¨æŠ€å·§

### æ•°æ®å¢å¼º
```python
transform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
```

### è¿ç§»å­¦ä¹ 
```python
# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = torchvision.models.resnet50(pretrained=True)

# å†»ç»“ç‰¹å¾æå–å±‚
for param in model.parameters():
    param.requires_grad = False

# æ›¿æ¢åˆ†ç±»å™¨
model.fc = nn.Linear(2048, num_classes)
```

### æ¨¡å‹å¯è§†åŒ–
```python
# å¯è§†åŒ–å·ç§¯æ ¸
def visualize_kernels(model):
    kernels = model.conv1.weight.data.cpu().numpy()
    # ç»˜åˆ¶å·ç§¯æ ¸å›¾åƒ
    plt.figure(figsize=(10, 10))
    for i in range(32):
        plt.subplot(6, 6, i+1)
        plt.imshow(kernels[i, 0], cmap='gray')
        plt.axis('off')
    plt.show()
```

## ğŸ“š å­¦ä¹ èµ„æº

### å´æ©è¾¾è¯¾ç¨‹
- [ç¬¬å››å‘¨ï¼šå·ç§¯ç¥ç»ç½‘ç»œ](https://www.coursera.org/learn/convolutional-neural-networks)

### ç»å…¸è®ºæ–‡
- [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) - AlexNet
- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) - VGG
- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) - ResNet

### åœ¨çº¿èµ„æº
- [CS231n: Convolutional Neural Networks](https://cs231n.github.io/)
- [CNN Explainer](https://poloclub.github.io/cnn-explainer/)
- [PyTorch Vision Tutorials](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html)

---
*æœ€è¿‘æ›´æ–°: {{ .Lastmod.Format "2006-01-02" }}*