+++
date = '2025-10-24T21:57:58+08:00'
draft = false
title = 'TensorFlowæ¡†æ¶'
comments = true
weight = 6
+++

# TensorFlowæ¡†æ¶

TensorFlowæ˜¯Googleå¼€å‘çš„å¼€æºæœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œä»¥å…¶å¼ºå¤§çš„è®¡ç®—å›¾ã€çµæ´»çš„APIå’Œä¸°å¯Œçš„ç”Ÿæ€ç³»ç»Ÿè€Œé—»åã€‚æœ¬ç« ç³»ç»Ÿä»‹ç»TensorFlowçš„æ ¸å¿ƒæ¦‚å¿µã€APIè®¾è®¡å’Œå®é™…åº”ç”¨ã€‚

## ğŸ¯ TensorFlowæ¦‚è¿°

### å‘å±•å†å²
- **2015å¹´**ï¼šTensorFlow 1.0å‘å¸ƒï¼ŒåŸºäºTheanoå’ŒCaffe
- **2019å¹´**ï¼šTensorFlow 2.0å‘å¸ƒï¼Œå¼ºè°ƒæ˜“ç”¨æ€§å’ŒEager Execution
- **2022å¹´**ï¼šTensorFlow 2.8+ï¼Œé›†æˆKerasä½œä¸ºé«˜çº§API

### æ ¸å¿ƒç‰¹æ€§
- **è®¡ç®—å›¾**ï¼šé™æ€å›¾å’ŒåŠ¨æ€å›¾æ··åˆæ¨¡å¼
- **è‡ªåŠ¨å¾®åˆ†**ï¼šè‡ªåŠ¨è®¡ç®—æ¢¯åº¦
- **åˆ†å¸ƒå¼è®­ç»ƒ**ï¼šæ”¯æŒå¤šGPUå’ŒTPUè®­ç»ƒ
- **ç”Ÿæ€ç³»ç»Ÿ**ï¼šTensorFlow Extended (TFX)ã€TensorFlow Liteç­‰

## ğŸ—ï¸ æ ¸å¿ƒæ¦‚å¿µ

### å¼ é‡ (Tensor)
TensorFlowä¸­çš„åŸºæœ¬æ•°æ®ç»“æ„ï¼š

```python
import tensorflow as tf

# æ ‡é‡
scalar = tf.constant(3.14)

# å‘é‡
vector = tf.constant([1, 2, 3])

# çŸ©é˜µ
matrix = tf.constant([[1, 2], [3, 4]])

# ä¸‰ç»´å¼ é‡
tensor_3d = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])

print(f"æ ‡é‡å½¢çŠ¶: {scalar.shape}")
print(f"å‘é‡å½¢çŠ¶: {vector.shape}")
print(f"çŸ©é˜µå½¢çŠ¶: {matrix.shape}")
print(f"ä¸‰ç»´å¼ é‡å½¢çŠ¶: {tensor_3d.shape}")
```

### è®¡ç®—å›¾ (Computation Graph)
TensorFlow 1.xçš„æ ¸å¿ƒæ¦‚å¿µï¼š

```python
# TensorFlow 1.x é£æ ¼
import tensorflow as tf

# æ„å»ºè®¡ç®—å›¾
a = tf.placeholder(tf.float32, name='a')
b = tf.placeholder(tf.float32, name='b')
c = tf.add(a, b, name='add')

# æ‰§è¡Œè®¡ç®—å›¾
with tf.Session() as sess:
    result = sess.run(c, feed_dict={a: 2.0, b: 3.0})
    print(f"2 + 3 = {result}")
```

### Eager Execution
TensorFlow 2.xçš„é»˜è®¤æ¨¡å¼ï¼š

```python
import tensorflow as tf

# å¯ç”¨Eager Executionï¼ˆTensorFlow 2.xé»˜è®¤å¯ç”¨ï¼‰
tf.config.run_functions_eagerly(True)

# ç«‹å³æ‰§è¡Œæ¨¡å¼
x = tf.constant([1, 2, 3])
y = tf.constant([4, 5, 6])
z = x + y  # ç«‹å³æ‰§è¡Œ

print(f"x + y = {z.numpy()}")
```

## ğŸš€ TensorFlow 2.x API

### Kerasé«˜çº§API
```python
import tensorflow as tf
from tensorflow import keras

# æ„å»ºæ¨¡å‹
model = keras.Sequential([
    keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

# ç¼–è¯‘æ¨¡å‹
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# æ¨¡å‹æ‘˜è¦
model.summary()
```

### è‡ªå®šä¹‰å±‚å’Œæ¨¡å‹
```python
class CustomLayer(keras.layers.Layer):
    def __init__(self, units=32, **kwargs):
        super(CustomLayer, self).__init__(**kwargs)
        self.units = units

    def build(self, input_shape):
        self.w = self.add_weight(
            shape=(input_shape[-1], self.units),
            initializer='random_normal',
            trainable=True
        )
        self.b = self.add_weight(
            shape=(self.units,),
            initializer='zeros',
            trainable=True
        )

    def call(self, inputs):
        return tf.nn.relu(tf.matmul(inputs, self.w) + self.b)

# ä½¿ç”¨è‡ªå®šä¹‰å±‚
model = keras.Sequential([
    CustomLayer(128),
    keras.layers.Dense(10, activation='softmax')
])
```

### è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯
```python
# è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯
def train_model(model, dataset, epochs=10):
    optimizer = tf.keras.optimizers.Adam()
    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()

    for epoch in range(epochs):
        epoch_loss = 0
        epoch_accuracy = 0

        for step, (x_batch, y_batch) in enumerate(dataset):
            with tf.GradientTape() as tape:
                predictions = model(x_batch, training=True)
                loss = loss_fn(y_batch, predictions)

            gradients = tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(zip(gradients, model.trainable_variables))

            epoch_loss += loss.numpy()
            epoch_accuracy += tf.reduce_mean(
                tf.cast(tf.equal(tf.argmax(predictions, axis=1), y_batch), tf.float32)
            ).numpy()

        print(f"Epoch {epoch}: Loss: {epoch_loss/(step+1):.4f}, "
              f"Accuracy: {epoch_accuracy/(step+1):.4f}")
```

## ğŸ“Š æ•°æ®å¤„ç†

### tf.data API
é«˜æ•ˆçš„æ•°æ®åŠ è½½å’Œé¢„å¤„ç†ï¼š

```python
import tensorflow as tf

# åˆ›å»ºæ•°æ®é›†
dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))

# æ•°æ®é¢„å¤„ç†
dataset = dataset.map(lambda x, y: (preprocess_image(x), y))

# æ‰¹å¤„ç†å’Œæ‰“ä¹±
dataset = dataset.shuffle(buffer_size=1000)
dataset = dataset.batch(batch_size=32)

# é¢„å–æ•°æ®
dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)

# è®­ç»ƒå¾ªç¯
for batch in dataset:
    # è®­ç»ƒæ­¥éª¤
    train_step(batch)
```

### æ•°æ®å¢å¼º
```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# å›¾åƒæ•°æ®å¢å¼º
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

# åº”ç”¨æ•°æ®å¢å¼º
datagen.fit(x_train)
```

## ğŸ¯ æ¨¡å‹è®­ç»ƒ

### å†…ç½®è®­ç»ƒå¾ªç¯
```python
# ä½¿ç”¨model.fitè¿›è¡Œè®­ç»ƒ
history = model.fit(
    x_train, y_train,
    batch_size=32,
    epochs=10,
    validation_data=(x_val, y_val),
    callbacks=[
        tf.keras.callbacks.EarlyStopping(patience=3),
        tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True),
        tf.keras.callbacks.TensorBoard(log_dir='./logs')
    ]
)
```

### å›è°ƒå‡½æ•°
```python
# è‡ªå®šä¹‰å›è°ƒå‡½æ•°
class CustomCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        if logs['val_accuracy'] > 0.95:
            print(f"\nè¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡ {logs['val_accuracy']:.4f}ï¼Œåœæ­¢è®­ç»ƒ")
            self.model.stop_training = True

# ä½¿ç”¨è‡ªå®šä¹‰å›è°ƒ
model.fit(x_train, y_train, callbacks=[CustomCallback()])
```

## ğŸ”§ æ¨¡å‹ä¿å­˜å’ŒåŠ è½½

### ä¿å­˜å®Œæ•´æ¨¡å‹
```python
# ä¿å­˜æ¨¡å‹
model.save('my_model.h5')
model.save('my_model')  # TensorFlow 2.xæ ¼å¼

# åŠ è½½æ¨¡å‹
loaded_model = tf.keras.models.load_model('my_model.h5')
loaded_model = tf.keras.models.load_model('my_model')
```

### ä¿å­˜æ¨¡å‹æƒé‡
```python
# ä¿å­˜æƒé‡
model.save_weights('model_weights.h5')

# åŠ è½½æƒé‡
model.load_weights('model_weights.h5')
```

### ä¿å­˜æ¨¡å‹æ¶æ„
```python
# ä¿å­˜æ¶æ„ä¸ºJSON
model_json = model.to_json()
with open('model.json', 'w') as json_file:
    json_file.write(model_json)

# ä»JSONåŠ è½½æ¶æ„
from tensorflow.keras.models import model_from_json
with open('model.json', 'r') as json_file:
    loaded_model_json = json_file.read()
loaded_model = model_from_json(loaded_model_json)
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### GPUåŠ é€Ÿ
```python
# æ£€æŸ¥GPUå¯ç”¨æ€§
print("GPUå¯ç”¨:", tf.config.list_physical_devices('GPU'))

# è®¾ç½®GPUå†…å­˜å¢é•¿
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)
```

### æ··åˆç²¾åº¦è®­ç»ƒ
```python
from tensorflow.keras.mixed_precision import experimental as mixed_precision

# å¯ç”¨æ··åˆç²¾åº¦
policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_policy(policy)

# æ„å»ºæ¨¡å‹ï¼ˆè‡ªåŠ¨ä½¿ç”¨æ··åˆç²¾åº¦ï¼‰
model = tf.keras.Sequential([...])
```

### åˆ†å¸ƒå¼è®­ç»ƒ
```python
# å¤šGPUè®­ç»ƒ
strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    model = create_model()
    model.compile(...)

# TPUè®­ç»ƒ
resolver = tf.distribute.cluster_resolver.TPUClusterResolver()
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)
```

## ğŸ¨ é«˜çº§ç‰¹æ€§

### è‡ªå®šä¹‰æŸå¤±å‡½æ•°
```python
def custom_loss(y_true, y_pred):
    # è‡ªå®šä¹‰æŸå¤±è®¡ç®—
    mse = tf.reduce_mean(tf.square(y_true - y_pred))
    mae = tf.reduce_mean(tf.abs(y_true - y_pred))
    return mse + 0.1 * mae

# ä½¿ç”¨è‡ªå®šä¹‰æŸå¤±
model.compile(optimizer='adam', loss=custom_loss)
```

### è‡ªå®šä¹‰æŒ‡æ ‡
```python
class F1Score(tf.keras.metrics.Metric):
    def __init__(self, name='f1_score', **kwargs):
        super(F1Score, self).__init__(name=name, **kwargs)
        self.true_positives = self.add_weight(name='tp', initializer='zeros')
        self.false_positives = self.add_weight(name='fp', initializer='zeros')
        self.false_negatives = self.add_weight(name='fn', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_pred = tf.cast(tf.greater(y_pred, 0.5), tf.float32)
        y_true = tf.cast(y_true, tf.float32)

        tp = tf.reduce_sum(y_true * y_pred)
        fp = tf.reduce_sum((1 - y_true) * y_pred)
        fn = tf.reduce_sum(y_true * (1 - y_pred))

        self.true_positives.assign_add(tp)
        self.false_positives.assign_add(fp)
        self.false_negatives.assign_add(fn)

    def result(self):
        precision = self.true_positives / (self.true_positives + self.false_positives + 1e-15)
        recall = self.true_positives / (self.true_positives + self.false_negatives + 1e-15)
        return 2 * precision * recall / (precision + recall + 1e-15)
```

## ğŸš€ éƒ¨ç½²å’Œç”Ÿäº§åŒ–

### TensorFlow Serving
```python
# ä¿å­˜æ¨¡å‹ç”¨äºServing
model.save('model/1')

# å¯åŠ¨TensorFlow Serving
# tensorflow_model_server --rest_api_port=8501 --model_name=my_model --model_base_path=/path/to/model
```

### TensorFlow Lite
```python
# è½¬æ¢ä¸ºTensorFlow Liteæ ¼å¼
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# ä¿å­˜æ¨¡å‹
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)
```

### TensorFlow.js
```python
# è½¬æ¢ä¸ºTensorFlow.jsæ ¼å¼
import tensorflowjs as tfjs
tfjs.converters.save_keras_model(model, 'tfjs_model')
```

## ğŸ“š å­¦ä¹ èµ„æº

### å®˜æ–¹æ–‡æ¡£
- [TensorFlowå®˜æ–¹æ–‡æ¡£](https://www.tensorflow.org/)
- [TensorFlowæŒ‡å—](https://www.tensorflow.org/guide)
- [TensorFlowæ•™ç¨‹](https://www.tensorflow.org/tutorials)

### å´æ©è¾¾è¯¾ç¨‹
- æ·±åº¦å­¦ä¹ è¯¾ç¨‹ä¸­å…³äºTensorFlowçš„éƒ¨åˆ†

### ç»å…¸èµ„æº
- [TensorFlowå®˜æ–¹ç¤ºä¾‹](https://github.com/tensorflow/examples)
- [TensorFlowæ¨¡å‹åº“](https://tfhub.dev/)
- [Kerasæ–‡æ¡£](https://keras.io/)

## ğŸ¯ æœ€ä½³å®è·µ

### ä»£ç ç»„ç»‡
```python
# æ¨èçš„é¡¹ç›®ç»“æ„
my_project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ splits/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ saved_models/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ utils/
â””â”€â”€ config/
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®
1. **ä½¿ç”¨tf.data API**ï¼šé«˜æ•ˆçš„æ•°æ®åŠ è½½
2. **æ‰¹å¤„ç†**ï¼šåˆç†è®¾ç½®æ‰¹å¤§å°
3. **GPUåˆ©ç”¨**ï¼šç›‘æ§GPUä½¿ç”¨ç‡
4. **æ¨¡å‹æ£€æŸ¥ç‚¹**ï¼šå®šæœŸä¿å­˜æ¨¡å‹
5. **è¶…å‚æ•°è°ƒä¼˜**ï¼šä½¿ç”¨TensorBoardå¯è§†åŒ–

### è°ƒè¯•æŠ€å·§
```python
# å¯ç”¨è°ƒè¯•æ¨¡å¼
tf.debugging.set_log_device_placement(True)

# æ£€æŸ¥å¼ é‡å½¢çŠ¶
print(x.shape)
print(y.shape)

# ä½¿ç”¨tf.printè°ƒè¯•
x = tf.print(x, [x], "xçš„å€¼:")
```

---

*æœ€è¿‘æ›´æ–°: {{ .Lastmod.Format "2006-01-02" }}*