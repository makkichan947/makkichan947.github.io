+++
date = '2025-10-24T21:39:04+08:00'
draft = false
title = 'ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ'
comments = true
weight = 5
+++

# ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ

ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGenerative Adversarial Networks, GANï¼‰æ˜¯ç”±Ian Goodfellowåœ¨2014å¹´æå‡ºçš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒçš„æ–¹å¼ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆæ•°æ®ï¼Œåœ¨å›¾åƒç”Ÿæˆã€é£æ ¼è¿ç§»ç­‰é¢†åŸŸå–å¾—äº†å·¨å¤§æˆåŠŸã€‚

## ğŸ¯ GANåŸºæœ¬åŸç†

### å¯¹æŠ—è®­ç»ƒæ€æƒ³
GANçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡ç”Ÿæˆå™¨ï¼ˆGeneratorï¼‰å’Œåˆ¤åˆ«å™¨ï¼ˆDiscriminatorï¼‰ä¹‹é—´çš„å¯¹æŠ—è®­ç»ƒæ¥å­¦ä¹ æ•°æ®åˆ†å¸ƒï¼š

- **ç”Ÿæˆå™¨G**ï¼šå­¦ä¹ çœŸå®æ•°æ®åˆ†å¸ƒï¼Œç”Ÿæˆé€¼çœŸçš„å‡æ ·æœ¬
- **åˆ¤åˆ«å™¨D**ï¼šåŒºåˆ†çœŸå®æ ·æœ¬å’Œç”Ÿæˆæ ·æœ¬
- **å¯¹æŠ—è¿‡ç¨‹**ï¼šç”Ÿæˆå™¨è¯•å›¾æ¬ºéª—åˆ¤åˆ«å™¨ï¼Œåˆ¤åˆ«å™¨è¯•å›¾æ­£ç¡®è¯†åˆ«

### æ•°å­¦åŸºç¡€

**ç”Ÿæˆå™¨ç›®æ ‡**ï¼š
$$\min_G \max_D V(D,G) = \mathbb{E}_{x \sim p_{data}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log (1 - D(G(z)))]$$

**æœ€ä¼˜åˆ¤åˆ«å™¨**ï¼š
$$D^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}$$

## ğŸ—ï¸ GANæ¶æ„è¯¦è§£

### ç”Ÿæˆå™¨ç»“æ„
ç”Ÿæˆå™¨é€šå¸¸é‡‡ç”¨è§£ç å™¨å¼çš„æ¶æ„ï¼š

```python
class Generator(nn.Module):
    def __init__(self, latent_dim, img_shape):
        super(Generator, self).__init__()

        self.model = nn.Sequential(
            # ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚
            nn.Linear(latent_dim, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),

            # ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚
            nn.Linear(128, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),

            # ç¬¬ä¸‰ä¸ªå…¨è¿æ¥å±‚
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),

            # è¾“å‡ºå±‚
            nn.Linear(512, int(np.prod(img_shape))),
            nn.Tanh()
        )

    def forward(self, z):
        img = self.model(z)
        img = img.view(img.size(0), *img_shape)
        return img
```

### åˆ¤åˆ«å™¨ç»“æ„
åˆ¤åˆ«å™¨é‡‡ç”¨åˆ†ç±»å™¨æ¶æ„ï¼š

```python
class Discriminator(nn.Module):
    def __init__(self, img_shape):
        super(Discriminator, self).__init__()

        self.model = nn.Sequential(
            # ç¬¬ä¸€ä¸ªå·ç§¯å±‚
            nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2),

            # ç¬¬äºŒä¸ªå·ç§¯å±‚
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2),

            # å…¨å±€å¹³å‡æ± åŒ–
            nn.AdaptiveAvgPool2d(1),

            # å…¨è¿æ¥å±‚
            nn.Linear(128, 1),
            nn.Sigmoid()
        )

    def forward(self, img):
        validity = self.model(img)
        return validity
```

## ğŸš€ è®­ç»ƒç®—æ³•

### æ ‡å‡†GANè®­ç»ƒ
```python
def train_gan(generator, discriminator, dataloader, num_epochs, latent_dim):
    # æŸå¤±å‡½æ•°
    adversarial_loss = nn.BCELoss()

    # ä¼˜åŒ–å™¨
    optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

    for epoch in range(num_epochs):
        for i, (real_imgs, _) in enumerate(dataloader):

            # çœŸå®å›¾åƒæ ‡ç­¾
            valid = torch.ones(real_imgs.size(0), 1, requires_grad=False)
            fake = torch.zeros(real_imgs.size(0), 1, requires_grad=False)

            # è®­ç»ƒåˆ¤åˆ«å™¨
            optimizer_D.zero_grad()

            # åˆ¤åˆ«å™¨å¯¹çœŸå®å›¾åƒçš„é¢„æµ‹
            real_loss = adversarial_loss(discriminator(real_imgs), valid)

            # ç”Ÿæˆå‡å›¾åƒ
            z = torch.randn(real_imgs.size(0), latent_dim)
            fake_imgs = generator(z)

            # åˆ¤åˆ«å™¨å¯¹å‡å›¾åƒçš„é¢„æµ‹
            fake_loss = adversarial_loss(discriminator(fake_imgs.detach()), fake)

            # åˆ¤åˆ«å™¨æ€»æŸå¤±
            d_loss = (real_loss + fake_loss) / 2
            d_loss.backward()
            optimizer_D.step()

            # è®­ç»ƒç”Ÿæˆå™¨
            optimizer_G.zero_grad()

            # ç”Ÿæˆå™¨è¯•å›¾æ¬ºéª—åˆ¤åˆ«å™¨
            g_loss = adversarial_loss(discriminator(fake_imgs), valid)
            g_loss.backward()
            optimizer_G.step()

        print(f"Epoch {epoch}: D_loss: {d_loss.item():.4f}, G_loss: {g_loss.item():.4f}")
```

## ğŸ¨ GANå˜ç§

### DCGAN (Deep Convolutional GAN)
- **å·ç§¯æ¶æ„**ï¼šä½¿ç”¨å·ç§¯å±‚æ›¿ä»£å…¨è¿æ¥å±‚
- **æ‰¹å½’ä¸€åŒ–**ï¼šç¨³å®šè®­ç»ƒè¿‡ç¨‹
- **æ”¹è¿›æ¿€æ´»**ï¼šç”Ÿæˆå™¨ä½¿ç”¨ReLUï¼Œåˆ¤åˆ«å™¨ä½¿ç”¨LeakyReLU

### WGAN (Wasserstein GAN)
- **Wassersteinè·ç¦»**ï¼šæ›´ç¨³å®šçš„è®­ç»ƒç›®æ ‡
- **æƒé‡è£å‰ª**ï¼šé™åˆ¶åˆ¤åˆ«å™¨æƒé‡èŒƒå›´
- **ç†è®ºä¿è¯**ï¼šé¿å…æ¨¡å¼å´©æºƒ

### CycleGAN
- **æ— é…å¯¹æ•°æ®**ï¼šå­¦ä¹ ä¸åŒåŸŸä¹‹é—´çš„æ˜ å°„
- **å¾ªç¯ä¸€è‡´æ€§**ï¼šç¡®ä¿è½¬æ¢çš„å¯é€†æ€§
- **åº”ç”¨**ï¼šå›¾åƒé£æ ¼è¿ç§»

### StyleGAN
- **é£æ ¼æ§åˆ¶**ï¼šé€šè¿‡AdaINæ§åˆ¶ç”Ÿæˆå›¾åƒçš„é£æ ¼
- **æ¸è¿›å¼å¢é•¿**ï¼šä»ä½åˆ†è¾¨ç‡åˆ°é«˜åˆ†è¾¨ç‡è®­ç»ƒ
- **é«˜è´¨é‡ç”Ÿæˆ**ï¼šç”Ÿæˆé«˜åˆ†è¾¨ç‡é€¼çœŸå›¾åƒ

## ğŸ¯ æŸå¤±å‡½æ•°

### æ ‡å‡†GANæŸå¤±
```python
# åˆ¤åˆ«å™¨æŸå¤±
d_real_loss = -torch.log(discriminator(real_imgs))
d_fake_loss = -torch.log(1 - discriminator(fake_imgs))
d_loss = (d_real_loss + d_fake_loss) / 2

# ç”Ÿæˆå™¨æŸå¤±
g_loss = -torch.log(discriminator(fake_imgs))
```

### WGANæŸå¤±
```python
# WGANä½¿ç”¨Wassersteinè·ç¦»
d_loss = -torch.mean(discriminator(real_imgs)) + torch.mean(discriminator(fake_imgs))
g_loss = -torch.mean(discriminator(fake_imgs))
```

### LSGANæŸå¤±
```python
# æœ€å°äºŒä¹˜GAN
d_real_loss = torch.mean((discriminator(real_imgs) - 1)**2)
d_fake_loss = torch.mean(discriminator(fake_imgs)**2)
d_loss = (d_real_loss + d_fake_loss) / 2

g_loss = torch.mean((discriminator(fake_imgs) - 1)**2)
```

## ğŸ”§ è®­ç»ƒæŠ€å·§

### æ¨¡å¼å´©æºƒé—®é¢˜
**é—®é¢˜**ï¼šç”Ÿæˆå™¨åªç”Ÿæˆæœ‰é™çš„æ ·æœ¬æ¨¡å¼

**è§£å†³æ–¹æ¡ˆ**ï¼š
- **Mini-batchåˆ¤åˆ«**ï¼šåˆ¤åˆ«å™¨ä½¿ç”¨å¤šä¸ªå‡æ ·æœ¬
- **ç‰¹å¾åŒ¹é…**ï¼šåŒ¹é…çœŸå®å’Œç”Ÿæˆæ•°æ®çš„ä¸­é—´ç‰¹å¾
- **è°±å½’ä¸€åŒ–**ï¼šç¨³å®šåˆ¤åˆ«å™¨è®­ç»ƒ

### æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
**é—®é¢˜**ï¼šåˆ¤åˆ«å™¨è¿‡å¼ºå¯¼è‡´ç”Ÿæˆå™¨æ¢¯åº¦æ¶ˆå¤±

**è§£å†³æ–¹æ¡ˆ**ï¼š
- **æ ‡ç­¾å¹³æ»‘**ï¼šä½¿ç”¨0.9ä»£æ›¿1.0ä½œä¸ºçœŸå®æ ‡ç­¾
- **å†å²å¹³å‡**ï¼šä¿å­˜åˆ¤åˆ«å™¨çš„å†å²ç‰ˆæœ¬
- **é¢‘ç‡åˆ†ç¦»**ï¼šåˆ†ç¦»é«˜é¢‘å’Œä½é¢‘ä¿¡æ¯

## ğŸ¨ åº”ç”¨é¢†åŸŸ

### å›¾åƒç”Ÿæˆ
- **äººè„¸ç”Ÿæˆ**ï¼šStyleGANç”Ÿæˆé€¼çœŸçš„äººè„¸å›¾åƒ
- **è‰ºæœ¯åˆ›ä½œ**ï¼šç”Ÿæˆå„ç§é£æ ¼çš„è‰ºæœ¯ä½œå“
- **æ•°æ®å¢å¼º**ï¼šä¸ºè®­ç»ƒæ•°æ®ç”Ÿæˆæ›´å¤šæ ·æœ¬

### å›¾åƒåˆ°å›¾åƒè½¬æ¢
- **é£æ ¼è¿ç§»**ï¼šå°†å›¾åƒè½¬æ¢ä¸ºä¸åŒè‰ºæœ¯é£æ ¼
- **è¶…åˆ†è¾¨ç‡**ï¼šå°†ä½åˆ†è¾¨ç‡å›¾åƒè½¬æ¢ä¸ºé«˜åˆ†è¾¨ç‡
- **å›¾åƒä¿®å¤**ï¼šä¿®å¤æŸåæˆ–ç¼ºå¤±çš„å›¾åƒéƒ¨åˆ†

### æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ
- **DALL-E**ï¼šæ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆå›¾åƒ
- **Stable Diffusion**ï¼šé«˜æ•ˆçš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹
- **Midjourney**ï¼šå•†ä¸šçº§å›¾åƒç”ŸæˆæœåŠ¡

### è§†é¢‘ç”Ÿæˆ
- **è§†é¢‘é¢„æµ‹**ï¼šé¢„æµ‹è§†é¢‘åºåˆ—çš„ä¸‹ä¸€å¸§
- **è§†é¢‘åˆæˆ**ï¼šç”Ÿæˆæ–°çš„è§†é¢‘å†…å®¹
- **åŠ¨ä½œè¿ç§»**ï¼šå°†åŠ¨ä½œä»ä¸€ä¸ªè§†é¢‘è¿ç§»åˆ°å¦ä¸€ä¸ª

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

### å®šé‡è¯„ä¼°
- **Inception Score (IS)**ï¼šè¯„ä¼°ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¤šæ ·æ€§
- **FrÃ©chet Inception Distance (FID)**ï¼šè®¡ç®—ç”Ÿæˆæ•°æ®ä¸çœŸå®æ•°æ®çš„è·ç¦»
- **Kernel Inception Distance (KID)**ï¼šæ”¹è¿›çš„FIDæŒ‡æ ‡

### å®šæ€§è¯„ä¼°
- **ç”¨æˆ·ç ”ç©¶**ï¼šäººç±»è¯„ä¼°ç”Ÿæˆå›¾åƒçš„è´¨é‡
- **å¤šæ ·æ€§åˆ†æ**ï¼šåˆ†æç”Ÿæˆæ ·æœ¬çš„å¤šæ ·æ€§
- **æ’å€¼å®éªŒ**ï¼šæµ‹è¯•æ½œåœ¨ç©ºé—´çš„è¿ç»­æ€§

## ğŸš€ ç¼–ç¨‹å®ç°

### å®Œæ•´GANè®­ç»ƒä»£ç 
```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# æ•°æ®é¢„å¤„ç†
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

# åŠ è½½MNISTæ•°æ®é›†
dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

# è¶…å‚æ•°
latent_dim = 100
img_shape = (1, 28, 28)
num_epochs = 100

# ç”Ÿæˆå™¨
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Linear(512, int(torch.prod(torch.tensor(img_shape)))),
            nn.Tanh()
        )

    def forward(self, z):
        img = self.model(z)
        img = img.view(img.size(0), *img_shape)
        return img

# åˆ¤åˆ«å™¨
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(int(torch.prod(torch.tensor(img_shape))), 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, img):
        img_flat = img.view(img.size(0), -1)
        validity = self.model(img_flat)
        return validity

# åˆå§‹åŒ–æ¨¡å‹
generator = Generator()
discriminator = Discriminator()

# æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
adversarial_loss = nn.BCELoss()
optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

# è®­ç»ƒå¾ªç¯
for epoch in range(num_epochs):
    for i, (real_imgs, _) in enumerate(dataloader):
        batch_size = real_imgs.size(0)

        # çœŸå®å’Œå‡æ ‡ç­¾
        valid = torch.ones(batch_size, 1, requires_grad=False)
        fake = torch.zeros(batch_size, 1, requires_grad=False)

        # è®­ç»ƒåˆ¤åˆ«å™¨
        optimizer_D.zero_grad()

        # åˆ¤åˆ«å™¨å¯¹çœŸå®å›¾åƒçš„é¢„æµ‹
        real_loss = adversarial_loss(discriminator(real_imgs), valid)

        # ç”Ÿæˆå‡å›¾åƒ
        z = torch.randn(batch_size, latent_dim)
        fake_imgs = generator(z)

        # åˆ¤åˆ«å™¨å¯¹å‡å›¾åƒçš„é¢„æµ‹
        fake_loss = adversarial_loss(discriminator(fake_imgs.detach()), fake)

        # åˆ¤åˆ«å™¨æ€»æŸå¤±
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward()
        optimizer_D.step()

        # è®­ç»ƒç”Ÿæˆå™¨
        optimizer_G.zero_grad()

        # ç”Ÿæˆå™¨è¯•å›¾æ¬ºéª—åˆ¤åˆ«å™¨
        g_loss = adversarial_loss(discriminator(fake_imgs), valid)
        g_loss.backward()
        optimizer_G.step()

    print(f"Epoch {epoch}: D_loss: {d_loss.item():.4f}, G_loss: {g_loss.item():.4f}")

print("è®­ç»ƒå®Œæˆï¼")
```

## ğŸ¯ ç”Ÿæˆæ ·æœ¬å¯è§†åŒ–
```python
def generate_samples(generator, num_samples=16):
    """ç”Ÿæˆå¹¶å¯è§†åŒ–æ ·æœ¬"""
    generator.eval()

    with torch.no_grad():
        # ç”Ÿæˆéšæœºå™ªå£°
        z = torch.randn(num_samples, latent_dim)

        # ç”Ÿæˆå›¾åƒ
        fake_imgs = generator(z)

        # è½¬æ¢ä¸ºnumpyæ•°ç»„ç”¨äºæ˜¾ç¤º
        fake_imgs = fake_imgs.detach().numpy()

        # åˆ›å»ºå›¾åƒç½‘æ ¼
        fig, axes = plt.subplots(4, 4, figsize=(8, 8))

        for i, ax in enumerate(axes.flat):
            if i < num_samples:
                ax.imshow(fake_imgs[i, 0], cmap='gray')
                ax.axis('off')

        plt.tight_layout()
        plt.show()

# ç”Ÿæˆæ ·æœ¬
generate_samples(generator)
```

## ğŸ“š å­¦ä¹ èµ„æº

### ç»å…¸è®ºæ–‡
- [Generative Adversarial Nets](https://arxiv.org/abs/1406.2661) - Ian Goodfellow (2014)
- [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434) - DCGAN
- [Wasserstein GAN](https://arxiv.org/abs/1701.07875) - WGAN
- [CycleGAN](https://arxiv.org/abs/1703.10593) - CycleGAN

### åœ¨çº¿èµ„æº
- [GANæ•™ç¨‹](https://www.tensorflow.org/tutorials/generative/dcgan)
- [PyTorch GANå®ç°](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)
- [GAN Zoo](https://github.com/hindupuravinash/the-gan-zoo) - å„ç§GANå˜ç§çš„å®ç°

### å´æ©è¾¾è¯¾ç¨‹
- æ·±åº¦å­¦ä¹ è¯¾ç¨‹ä¸­å…³äºç”Ÿæˆæ¨¡å‹çš„éƒ¨åˆ†

## ğŸ”§ å®ç”¨æŠ€å·§

### è¶…å‚æ•°è°ƒä¼˜
- **å­¦ä¹ ç‡**ï¼šç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨é€šå¸¸ä½¿ç”¨ç›¸åŒæˆ–ç›¸è¿‘çš„å­¦ä¹ ç‡
- **æ‰¹å¤§å°**ï¼šå½±å“è®­ç»ƒç¨³å®šæ€§å’Œç”Ÿæˆè´¨é‡
- **æ½œåœ¨ç»´åº¦**ï¼šå½±å“ç”Ÿæˆæ ·æœ¬çš„å¤šæ ·æ€§

### æ¨¡å‹è°ƒè¯•
- **ç›‘æ§æŸå¤±**ï¼šåˆ¤åˆ«å™¨å’Œç”Ÿæˆå™¨æŸå¤±åº”è¯¥åœ¨åˆç†èŒƒå›´å†…æ³¢åŠ¨
- **æ ·æœ¬è´¨é‡**ï¼šå®šæœŸæ£€æŸ¥ç”Ÿæˆæ ·æœ¬çš„è´¨é‡
- **æ¨¡å¼å´©æºƒæ£€æµ‹**ï¼šç¡®ä¿ç”Ÿæˆæ ·æœ¬å…·æœ‰è¶³å¤Ÿçš„å¤šæ ·æ€§

---

*æœ€è¿‘æ›´æ–°: {{ .Lastmod.Format "2006-01-02" }}*