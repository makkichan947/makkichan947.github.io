+++
title = "è½¯ä»¶åŒ…ä¸‹è½½"
date = "2025-10-28"
description = "ä¸‹è½½LFSæ„å»ºæ‰€éœ€çš„æ‰€æœ‰æºç åŒ…"
weight = 3
+++

# è½¯ä»¶åŒ…ä¸‹è½½

LFSæ„å»ºéœ€è¦ä¸‹è½½å¤§é‡çš„æºç åŒ…ã€‚æœ¬ç« å°†ä»‹ç»å¦‚ä½•ä¸‹è½½ã€éªŒè¯å’Œç®¡ç†è¿™äº›è½¯ä»¶åŒ…ï¼Œç¡®ä¿æ„å»ºè¿‡ç¨‹çš„é¡ºåˆ©è¿›è¡Œã€‚

## ğŸ“¦ åŒ…åˆ—è¡¨æ¦‚è¿°

### LFS 11.3 æ‰€éœ€åŒ…

LFS 11.3 ç‰ˆæœ¬éœ€è¦å¤§çº¦70ä¸ªè½¯ä»¶åŒ…ï¼ŒåŒ…æ‹¬ï¼š

- **åŸºç¡€å·¥å…·**ï¼šBinutils, GCC, Glibc, Makeç­‰
- **ç³»ç»Ÿåº“**ï¼šNcurses, Readline, Zlibç­‰
- **æ ¸å¿ƒå·¥å…·**ï¼šCoreutils, Util-linux, E2fsprogsç­‰
- **ç½‘ç»œå·¥å…·**ï¼šOpenssl, Curl, Wgetç­‰
- **æ–‡æ¡£å·¥å…·**ï¼šMan-pages, Texinfoç­‰

### åŒ…åˆ†ç±»

| ç±»åˆ« | æ•°é‡ | æè¿° |
|------|------|------|
| å·¥å…·é“¾ | ~15 | ç¼–è¯‘å™¨ã€é“¾æ¥å™¨ã€æ±‡ç¼–å™¨ |
| åŸºç¡€å·¥å…· | ~20 | ç³»ç»Ÿæ ¸å¿ƒå·¥å…· |
| åº“æ–‡ä»¶ | ~15 | ç³»ç»Ÿåº“å’Œä¾èµ– |
| æ–‡æ¡£ | ~5 | æ‰‹å†Œé¡µå’Œæ–‡æ¡£ |
| å…¶ä»– | ~15 | ç½‘ç»œå·¥å…·ã€å‹ç¼©å·¥å…·ç­‰ |

## ğŸ”— ä¸‹è½½æ–¹æ³•

### å®˜æ–¹ä¸‹è½½è„šæœ¬
```bash
# åˆ›å»ºä¸‹è½½ç›®å½•
mkdir -pv $LFS/sources

# è®¾ç½®æ­£ç¡®çš„æƒé™
chown -v lfs:lfs $LFS/sources

# åˆ‡æ¢åˆ°lfsç”¨æˆ·
su - lfs

# ä¸‹è½½wget-listæ–‡ä»¶
cd $LFS/sources
wget http://www.linuxfromscratch.org/lfs/view/stable/wget-list

# ä¸‹è½½md5sumsæ–‡ä»¶ï¼ˆç”¨äºéªŒè¯ï¼‰
wget http://www.linuxfromscratch.org/lfs/view/stable/md5sums

# ä½¿ç”¨wgetæ‰¹é‡ä¸‹è½½
wget --input-file=wget-list --continue --directory-prefix=$LFS/sources
```

### æ‰‹åŠ¨ä¸‹è½½é‡è¦åŒ…
```bash
# å¦‚æœç½‘ç»œé—®é¢˜ï¼Œå¯ä»¥æ‰‹åŠ¨ä¸‹è½½å…³é”®åŒ…
cd $LFS/sources

# Binutils
wget https://ftp.gnu.org/gnu/binutils/binutils-2.40.tar.xz

# GCC
wget https://ftp.gnu.org/gnu/gcc/gcc-12.2.0/gcc-12.2.0.tar.xz

# Glibc
wget https://ftp.gnu.org/gnu/glibc/glibc-2.37.tar.xz

# Linuxå†…æ ¸
wget https://www.kernel.org/pub/linux/kernel/v6.x/linux-6.1.11.tar.xz

# å…¶ä»–é‡è¦åŒ…
wget https://ftp.gnu.org/gnu/gmp/gmp-6.2.1.tar.xz
wget https://ftp.gnu.org/gnu/mpfr/mpfr-4.2.0.tar.xz
wget https://ftp.gnu.org/gnu/mpc/mpc-1.3.1.tar.xz
```

### å›½å†…é•œåƒæº
```bash
# ä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿä¸‹è½½
cd $LFS/sources

# æ¸…åå¤§å­¦é•œåƒ
wget -c https://mirrors.tuna.tsinghua.edu.cn/lfs/lfs-packages/11.3/binutils-2.40.tar.xz

# ä¸­ç§‘å¤§é•œåƒ
wget -c https://mirrors.ustc.edu.cn/lfs/lfs-packages/11.3/gcc-12.2.0.tar.xz

# æ‰¹é‡ä¸‹è½½è„šæœ¬ï¼ˆä½¿ç”¨å›½å†…é•œåƒï¼‰
cat > download_lfs_packages.sh << 'EOF'
#!/bin/bash
# LFSåŒ…ä¸‹è½½è„šæœ¬ï¼ˆå›½å†…é•œåƒï¼‰

MIRRORS=(
    "https://mirrors.tuna.tsinghua.edu.cn/lfs/lfs-packages/11.3/"
    "https://mirrors.ustc.edu.cn/lfs/lfs-packages/11.3/"
    "https://mirrors.huaweicloud.com/lfs/lfs-packages/11.3/"
)

PACKAGES=(
    "binutils-2.40.tar.xz"
    "gcc-12.2.0.tar.xz"
    "glibc-2.37.tar.xz"
    "linux-6.1.11.tar.xz"
    "gmp-6.2.1.tar.xz"
    "mpfr-4.2.0.tar.xz"
    "mpc-1.3.1.tar.xz"
    # æ·»åŠ æ›´å¤šåŒ…...
)

download_package() {
    local package=$1
    local success=0

    for mirror in "${MIRRORS[@]}"; do
        echo "å°è¯•ä» $mirror ä¸‹è½½ $package..."
        if wget -c "$mirror$package" -O "$package"; then
            echo "$package ä¸‹è½½æˆåŠŸ"
            success=1
            break
        else
            echo "$package ä» $mirror ä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªé•œåƒ"
        fi
    done

    if [ $success -eq 0 ]; then
        echo "ERROR: $package ä¸‹è½½å¤±è´¥"
        return 1
    fi

    return 0
}

# ä¸‹è½½æ‰€æœ‰åŒ…
for package in "${PACKAGES[@]}"; do
    if [ ! -f "$package" ]; then
        download_package "$package" || exit 1
    else
        echo "$package å·²å­˜åœ¨ï¼Œè·³è¿‡"
    fi
done

echo "æ‰€æœ‰åŒ…ä¸‹è½½å®Œæˆ"
EOF

chmod +x download_lfs_packages.sh
./download_lfs_packages.sh
```

## ğŸ” åŒ…éªŒè¯

### MD5æ ¡éªŒå’ŒéªŒè¯
```bash
# éªŒè¯ä¸‹è½½çš„åŒ…
cd $LFS/sources

# ä½¿ç”¨md5suméªŒè¯
md5sum -c md5sums

# æˆ–è€…é€ä¸ªéªŒè¯
md5sum binutils-2.40.tar.xz
# æ¯”è¾ƒè¾“å‡ºä¸md5sumsæ–‡ä»¶ä¸­çš„å€¼
```

### SHA256éªŒè¯
```bash
# å¦‚æœæœ‰SHA256æ ¡éªŒå’Œæ–‡ä»¶
wget http://www.linuxfromscratch.org/lfs/view/stable/sha256sums

# ä½¿ç”¨sha256suméªŒè¯
sha256sum -c sha256sums
```

### GPGç­¾åéªŒè¯
```bash
# ä¸‹è½½GPGç­¾åæ–‡ä»¶
wget https://ftp.gnu.org/gnu/binutils/binutils-2.40.tar.xz.sig

# å¯¼å…¥GPGå¯†é’¥
gpg --keyserver keyserver.ubuntu.com --recv-keys [å¯†é’¥ID]

# éªŒè¯ç­¾å
gpg --verify binutils-2.40.tar.xz.sig binutils-2.40.tar.xz
```

## ğŸ“ åŒ…ç®¡ç†

### åŒ…æ¸…å•ç®¡ç†
```bash
# åˆ›å»ºåŒ…æ¸…å•
cd $LFS/sources

# ç”Ÿæˆå·²ä¸‹è½½åŒ…çš„æ¸…å•
ls -1 *.tar.* | sort > package_inventory.txt

# ç”ŸæˆåŒ…å¤§å°ç»Ÿè®¡
du -sh *.tar.* | sort -h > package_sizes.txt

# ç”ŸæˆåŒ…ç±»å‹ç»Ÿè®¡
ls -1 *.tar.* | sed 's/.*\.//' | sort | uniq -c > package_types.txt
```

### åŒ…å¤‡ä»½å’Œæ¢å¤
```bash
# åˆ›å»ºåŒ…å¤‡ä»½
cd $LFS

# å‹ç¼©æ‰€æœ‰æºç åŒ…
tar -czf sources_backup.tar.gz sources/

# å¤‡ä»½åˆ°å¤–éƒ¨å­˜å‚¨
cp sources_backup.tar.gz /path/to/external/drive/

# ä»å¤‡ä»½æ¢å¤
# tar -xzf /path/to/backup/sources_backup.tar.gz -C $LFS/
```

### å¢é‡ä¸‹è½½
```bash
# æ£€æŸ¥ç¼ºå¤±çš„åŒ…
cd $LFS/sources

# æ¯”è¾ƒæœ¬åœ°åŒ…ä¸wget-list
comm -23 <(sort wget-list | sed 's|.*/||') <(ls *.tar.* | sort) > missing_packages.txt

# ä¸‹è½½ç¼ºå¤±çš„åŒ…
if [ -s missing_packages.txt ]; then
    echo "å‘ç°ç¼ºå¤±çš„åŒ…ï¼Œæ­£åœ¨ä¸‹è½½..."
    wget --input-file=missing_packages.txt --continue
else
    echo "æ‰€æœ‰åŒ…éƒ½å·²ä¸‹è½½"
fi
```

## ğŸ—‚ï¸ åŒ…ç»„ç»‡

### æŒ‰é˜¶æ®µç»„ç»‡åŒ…
```bash
# åˆ›å»ºé˜¶æ®µç›®å½•
cd $LFS/sources

mkdir -p toolchain base_system system_libs documentation networking

# ç§»åŠ¨åŒ…åˆ°å¯¹åº”ç›®å½•
# å·¥å…·é“¾åŒ…
mv binutils-* gcc-* glibc-* gmp-* mpfr-* mpc-* toolchain/

# åŸºç¡€ç³»ç»ŸåŒ…
mv coreutils-* util-linux-* e2fsprogs-* base_system/

# ç³»ç»Ÿåº“
mv ncurses-* readline-* zlib-* system_libs/

# ç½‘ç»œå·¥å…·
mv openssl-* curl-* wget-* networking/
```

### åŒ…ä¾èµ–å›¾
```bash
# ç”ŸæˆåŒ…ä¾èµ–å…³ç³»å›¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
cat > package_dependencies.dot << 'EOF'
digraph LFS_Dependencies {
    rankdir=LR;

    // å·¥å…·é“¾é˜¶æ®µ
    binutils -> gcc
    gmp -> gcc
    mpfr -> gcc
    mpc -> gcc
    gcc -> glibc

    // åŸºç¡€å·¥å…·é˜¶æ®µ
    glibc -> coreutils
    glibc -> util_linux
    coreutils -> bash
    util_linux -> e2fsprogs

    // ç³»ç»Ÿåº“é˜¶æ®µ
    glibc -> ncurses
    ncurses -> readline
    glibc -> zlib

    // ç½‘ç»œå·¥å…·é˜¶æ®µ
    openssl -> curl
    zlib -> curl
    curl -> wget
}
EOF

# ç”Ÿæˆå¯è§†åŒ–å›¾ï¼ˆéœ€è¦graphvizï¼‰
# dot -Tpng package_dependencies.dot -o dependencies.png
```

## ğŸš€ é«˜çº§ä¸‹è½½æŠ€å·§

### å¹¶è¡Œä¸‹è½½
```bash
# ä½¿ç”¨aria2è¿›è¡Œå¹¶è¡Œä¸‹è½½
# å®‰è£…aria2
sudo pacman -S aria2  # Arch
sudo apt install aria2  # Ubuntu

# åˆ›å»ºaria2ä¸‹è½½åˆ—è¡¨
cat > lfs_packages.txt << 'EOF'
https://ftp.gnu.org/gnu/binutils/binutils-2.40.tar.xz
https://ftp.gnu.org/gnu/gcc/gcc-12.2.0/gcc-12.2.0.tar.xz
https://ftp.gnu.org/gnu/glibc/glibc-2.37.tar.xz
# æ·»åŠ æ›´å¤šURL...
EOF

# å¹¶è¡Œä¸‹è½½ï¼ˆ10ä¸ªè¿æ¥ï¼‰
aria2c -i lfs_packages.txt -j 10 -d $LFS/sources
```

### æ–­ç‚¹ç»­ä¼ å’Œé‡è¯•
```bash
# åˆ›å»ºæ™ºèƒ½ä¸‹è½½è„šæœ¬
cat > smart_download.sh << 'EOF'
#!/bin/bash
# æ™ºèƒ½ä¸‹è½½è„šæœ¬ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œé‡è¯•

URL=$1
OUTPUT=$2
MAX_RETRIES=3
RETRY_DELAY=5

for ((i=1; i<=MAX_RETRIES; i++)); do
    echo "å°è¯•ä¸‹è½½ $URL (ç¬¬ $i æ¬¡)..."

    if wget -c "$URL" -O "$OUTPUT"; then
        echo "ä¸‹è½½æˆåŠŸ: $OUTPUT"
        exit 0
    else
        echo "ä¸‹è½½å¤±è´¥ï¼Œ$RETRY_DELAY ç§’åé‡è¯•..."
        sleep $RETRY_DELAY
    fi
done

echo "ERROR: ä¸‹è½½å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°"
exit 1
EOF

chmod +x smart_download.sh

# ä½¿ç”¨æ™ºèƒ½ä¸‹è½½
./smart_download.sh https://ftp.gnu.org/gnu/binutils/binutils-2.40.tar.xz binutils-2.40.tar.xz
```

### ä»£ç†è®¾ç½®
```bash
# è®¾ç½®wgetä»£ç†
export http_proxy=http://proxy.example.com:8080
export https_proxy=http://proxy.example.com:8080

# æˆ–è€…åœ¨wgetrcä¸­è®¾ç½®
echo "http_proxy = http://proxy.example.com:8080" >> ~/.wgetrc
echo "https_proxy = http://proxy.example.com:8080" >> ~/.wgetrc

# ä½¿ç”¨ä»£ç†ä¸‹è½½
wget --proxy=on http://www.linuxfromscratch.org/lfs/view/stable/wget-list
```

## ğŸ“Š ä¸‹è½½ç›‘æ§

### ä¸‹è½½è¿›åº¦ç›‘æ§
```bash
# å®æ—¶ç›‘æ§ä¸‹è½½è¿›åº¦
watch -n 5 'ls -lh $LFS/sources/*.tar.* | tail -10'

# ä¸‹è½½ç»Ÿè®¡
cat > download_stats.sh << 'EOF'
#!/bin/bash
# ä¸‹è½½ç»Ÿè®¡è„šæœ¬

SOURCES_DIR=$LFS/sources

echo "=== LFSåŒ…ä¸‹è½½ç»Ÿè®¡ ==="
echo "æ€»åŒ…æ•°é‡: $(ls $SOURCES_DIR/*.tar.* 2>/dev/null | wc -l)"
echo "æ€»å¤§å°: $(du -sh $SOURCES_DIR 2>/dev/null | cut -f1)"
echo ""

echo "åŒ…ç±»å‹åˆ†å¸ƒ:"
ls $SOURCES_DIR/*.tar.* 2>/dev/null | sed 's/.*\.//' | sort | uniq -c | sort -nr

echo ""
echo "æœ€å¤§åŒ…:"
ls -lh $SOURCES_DIR/*.tar.* 2>/dev/null | sort -k5 -hr | head -5

echo ""
echo "ä¸‹è½½å®Œæˆç‡:"
total=$(wc -l < wget-list 2>/dev/null || echo "0")
downloaded=$(ls $SOURCES_DIR/*.tar.* 2>/dev/null | wc -l)
echo "$downloaded / $total ($(echo "scale=2; $downloaded*100/$total" | bc -l)%)"
EOF

chmod +x download_stats.sh
./download_stats.sh
```

### è‡ªåŠ¨åŒ–ä¸‹è½½ç®¡ç†
```bash
# åˆ›å»ºä¸‹è½½ç®¡ç†è„šæœ¬
cat > download_manager.sh << 'EOF'
#!/bin/bash
# LFSä¸‹è½½ç®¡ç†å™¨

set -e

SOURCES_DIR=$LFS/sources
LOG_FILE=$SOURCES_DIR/download.log

log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $*" | tee -a "$LOG_FILE"
}

# æ£€æŸ¥ç½‘ç»œè¿æ¥
check_network() {
    if ! ping -c 1 google.com >/dev/null 2>&1; then
        log "ERROR: ç½‘ç»œè¿æ¥å¤±è´¥"
        exit 1
    fi
}

# ä¸‹è½½å•ä¸ªåŒ…
download_package() {
    local url=$1
    local filename=$(basename "$url")

    if [ -f "$SOURCES_DIR/$filename" ]; then
        log "åŒ…å·²å­˜åœ¨: $filename"
        return 0
    fi

    log "ä¸‹è½½: $filename"
    if wget -c "$url" -O "$SOURCES_DIR/$filename" --timeout=30 --tries=3; then
        log "æˆåŠŸ: $filename"
        return 0
    else
        log "å¤±è´¥: $filename"
        return 1
    fi
}

# ä¸»ä¸‹è½½å‡½æ•°
main() {
    log "å¼€å§‹LFSåŒ…ä¸‹è½½"

    check_network

    mkdir -p "$SOURCES_DIR"

    # ä¸‹è½½wget-list
    if [ ! -f "$SOURCES_DIR/wget-list" ]; then
        log "ä¸‹è½½wget-list..."
        download_package "http://www.linuxfromscratch.org/lfs/view/stable/wget-list" || exit 1
    fi

    # ä¸‹è½½md5sums
    if [ ! -f "$SOURCES_DIR/md5sums" ]; then
        log "ä¸‹è½½md5sums..."
        download_package "http://www.linuxfromscratch.org/lfs/view/stable/md5sums" || exit 1
    fi

    # æ‰¹é‡ä¸‹è½½åŒ…
    local success_count=0
    local total_count=0

    while read -r url; do
        [ -z "$url" ] && continue
        [ "${url:0:1}" = "#" ] && continue

        total_count=$((total_count + 1))

        if download_package "$url"; then
            success_count=$((success_count + 1))
        fi

        # æ˜¾ç¤ºè¿›åº¦
        echo -ne "\rè¿›åº¦: $success_count/$total_count"

    done < "$SOURCES_DIR/wget-list"

    echo "" # æ–°è¡Œ

    # éªŒè¯ä¸‹è½½
    log "éªŒè¯ä¸‹è½½çš„åŒ…..."
    cd "$SOURCES_DIR"
    if md5sum -c md5sums >/dev/null 2>&1; then
        log "æ‰€æœ‰åŒ…éªŒè¯é€šè¿‡"
    else
        log "WARNING: éƒ¨åˆ†åŒ…éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥"
    fi

    log "ä¸‹è½½å®Œæˆ: $success_count/$total_count æˆåŠŸ"
}

main "$@"
EOF

chmod +x download_manager.sh
./download_manager.sh
```

## ğŸš¨ å¸¸è§é—®é¢˜

### ç½‘ç»œé—®é¢˜
```bash
# å¦‚æœé‡åˆ°ç½‘ç»œè¶…æ—¶ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´
wget --timeout=60 --tries=5 http://example.com/package.tar.xz

# ä½¿ç”¨ä¸åŒçš„é•œåƒæº
# ä¿®æ”¹wget-listä¸­çš„URLä¸ºå›½å†…é•œåƒ
sed -i 's|https://ftp.gnu.org|https://mirrors.tuna.tsinghua.edu.cn|g' wget-list
```

### ç£ç›˜ç©ºé—´ä¸è¶³
```bash
# æ£€æŸ¥å¯ç”¨ç©ºé—´
df -h $LFS

# å¦‚æœç©ºé—´ä¸è¶³ï¼Œæ¸…ç†ä¸éœ€è¦çš„æ–‡ä»¶
rm -rf $LFS/sources/temp/*
```

### åŒ…æŸå
```bash
# é‡æ–°ä¸‹è½½æŸåçš„åŒ…
cd $LFS/sources
md5sum -c md5sums | grep FAILED

# åˆ é™¤å¹¶é‡æ–°ä¸‹è½½å¤±è´¥çš„åŒ…
# rm failed_package.tar.xz
# wget [URL]
```

## ğŸ“š ç›¸å…³èµ„æº

- [LFSå®˜æ–¹æ–‡æ¡£ - åŒ…ä¸‹è½½](http://www.linuxfromscratch.org/lfs/view/stable/chapter03/chapter03.html)
- [LFS wget-list](http://www.linuxfromscratch.org/lfs/view/stable/wget-list)
- [LFS md5sums](http://www.linuxfromscratch.org/lfs/view/stable/md5sums)

---

*æœ€è¿‘æ›´æ–°: {{ .Lastmod.Format "2006-01-02" }}*